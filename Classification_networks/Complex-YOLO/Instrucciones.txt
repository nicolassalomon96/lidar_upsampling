*Crear ./checkpoints/complexer_yolo y colocar el archivo de checkpoint generado durante el entrenamiento
Ejemplo: ./checkpoints/complexer_yolo/Model_complexer_yolo_epoch_300.pth

*En ./dataset/kitti deberá colocarse el dataset de detección de objetos 3D de kitti.
Link de descarga: https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d

Mínimamente debe descargarse:
	- Imágenes de la cámara izquierda (12GB)
	- Nube de puntos del LIDAR Velodyne (29GB)
	- Etiquetas de entrenamiento (5 MB)
	- Archivos de calibración de la cámara (16MB)

El directorio "dataset" deberá tener la siguiente estructura:

dataset/
  └──kitti/
	├──ImageSets/
	       ├── train.txt
               └── val.txt
        ├──training/
		├──calib/
		     └── Archivos de calibración de entrenamiento		
		├──image_2/
		     └── Imágenes de entrenamiento de la cámara (solo para la visualización final)
		├──label_2/
		     └── Etiquetas de entrenamiento
		└──velodyne/
		     └── Nube de puntos para entrenamiento
	└──testing/
		├──calib/
		     └── Archivos de calibración de prueba		
		├──image_2/
		     └── Imágenes de prueba de la cámara (solo para la visualización final)
		└──velodyne/
		     └── Nube de puntos para prueba
	└──classes_names.txt