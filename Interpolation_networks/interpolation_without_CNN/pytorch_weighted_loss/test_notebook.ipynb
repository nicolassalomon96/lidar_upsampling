{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook con fragmentos de códigos empleados para probar conceptos antes de aplicarlos al código final. No tener en cuenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "\n",
    "sys.path.append(r'D:\\Nicolas\\Posgrado\\Trabajos y Tesis\\LIDAR\\LIDAR_super_resolution\\Scripts\\otras_arquitecturas\\3_pytorch_interpolation')\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchsummary import summary\n",
    "import time\n",
    "#import kaolin\n",
    "#from data_gen_distance import *\n",
    "from pointcloud_utils_functions_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[[1.0,2.0,3.0,4.0,5.0], [5.0,6.0,7.0,8.0,9.0], [9.0,8.0,7.0,6.0,5.0], [5.0,4.0,3.0,2.0,1.0], [1.0,1.0,1.0,1.0,1.0]]]).unsqueeze(0)\n",
    "\n",
    "hr = torch.ones((1, 1, 10, 5))\n",
    "row_pos, column_pos = torch.where(hr[0,0] >= 0.0)\n",
    "odd_row_pos = row_pos[row_pos % 2 != 0] #/ row_pos.max()\n",
    "column_pos = column_pos[:column_pos.shape[0]//2] #/ column_pos.max()\n",
    "new_pixel_coords = torch.Tensor(list(zip(odd_row_pos, column_pos))[:-5])\n",
    "\n",
    "def get_windows(x, new_pixel_coords, upscaling_factor=2):\n",
    "    #def __init__(self, upsampling_factor=2, n_channels=1, padding=(0,1), stride=(1,1)): \n",
    "    #padding:(agregar n filas, agregar n columnas)\n",
    "    #stride(de a cuantas filas me muevo:de a cuantas columnas me muevo)\n",
    "    kernel_size = (4,3)\n",
    "    padding = (1,1)\n",
    "    stride = (1,1)\n",
    "    new_pixel_coords_batch = new_pixel_coords.unsqueeze(0).repeat(x.shape[0],1,1)\n",
    "\n",
    "    if upscaling_factor == 2:\n",
    "        windows = F.unfold(x, kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "        windows = windows.transpose(1, 2) #Obtener los valores de la ventana o kernel ordenados por fila, donde cada fila representa una ventana serializada\n",
    "        windows = torch.dstack((windows, new_pixel_coords_batch))\n",
    "    else:\n",
    "        print(\"ERROR: Wrong Upsampling factor\")\n",
    "    return windows\n",
    "\n",
    "windows = get_windows(x, new_pixel_coords)\n",
    "print(windows.shape)\n",
    "print(x.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(64.4298)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = torch.tensor([61.4734, 19.1356, -2.4600])\n",
    "print(p1.shape)\n",
    "torch.linalg.norm(p1, 2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0143545219784835\n",
      "tensor([24.6006], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import kaolin\n",
    "\n",
    "p1 = np.array([[[8.8977, 4.1709, 1.2839]]])\n",
    "p2 = np.array([[[6.9340, 6.1152, 3.4435]]])\n",
    "\n",
    "def chamfer_distance(points1, points2):\n",
    "    # Calcular las distancias desde cada punto en points1 al conjunto points2\n",
    "    distances1to2 = np.min(np.linalg.norm(points1[:, np.newaxis] - points2, axis=-1), axis=1)\n",
    "    \n",
    "    # Calcular las distancias desde cada punto en points2 al conjunto points1\n",
    "    distances2to1 = np.min(np.linalg.norm(points2[:, np.newaxis] - points1, axis=-1), axis=1)\n",
    "    \n",
    "    # Sumar las distancias mínimas en ambas direcciones para obtener la distancia de Chamfer\n",
    "    chamfer_dist = np.sum(distances1to2) + np.sum(distances2to1)\n",
    "    \n",
    "    return chamfer_dist\n",
    "\n",
    "print(chamfer_distance(p1[0],p2[0]))\n",
    "\n",
    "p1 = torch.tensor([[[8.8977, 4.1709, 1.2839]]])\n",
    "p2 = torch.tensor([[[6.9340, 6.1152, 3.4435]]])\n",
    "dist = kaolin.metrics.pointcloud.chamfer_distance(p1.to('cuda'), p2.to('cuda'), squared=True)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>truncated</th>\n",
       "      <th>occluded</th>\n",
       "      <th>alpha</th>\n",
       "      <th>bbox_left</th>\n",
       "      <th>bbox_top</th>\n",
       "      <th>bbox_right</th>\n",
       "      <th>bbox_bottom</th>\n",
       "      <th>height_object</th>\n",
       "      <th>width_object</th>\n",
       "      <th>length_object</th>\n",
       "      <th>location_x_camera</th>\n",
       "      <th>location_y_camera</th>\n",
       "      <th>location_z_camera</th>\n",
       "      <th>rotation_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>46.17</td>\n",
       "      <td>196.15</td>\n",
       "      <td>328.40</td>\n",
       "      <td>286.09</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.71</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-8.15</td>\n",
       "      <td>2.06</td>\n",
       "      <td>14.12</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>466.96</td>\n",
       "      <td>184.85</td>\n",
       "      <td>522.12</td>\n",
       "      <td>207.02</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.52</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-7.84</td>\n",
       "      <td>2.28</td>\n",
       "      <td>49.04</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type  truncated  occluded  alpha  bbox_left  bbox_top  bbox_right  \\\n",
       "0  Car        0.0         0   0.50      46.17    196.15      328.40   \n",
       "1  Car        0.0         1  -2.99     466.96    184.85      522.12   \n",
       "\n",
       "   bbox_bottom  height_object  width_object  length_object  location_x_camera  \\\n",
       "0       286.09           1.56          1.71            4.5              -8.15   \n",
       "1       207.02           1.44          1.52            3.5              -7.84   \n",
       "\n",
       "   location_y_camera  location_z_camera  rotation_y  \n",
       "0               2.06              14.12       -0.02  \n",
       "1               2.28              49.04        3.13  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = r'D:\\Nicolas\\Posgrado\\Trabajos y Tesis\\LIDAR\\Datasets LIDAR\\kitti\\kitti_3d_object\\training'\n",
    "pointcloud_file = '000034'\n",
    "pointcloud_fullpath = os.path.join(dataset_path, 'velodyne', rf'{pointcloud_file}.bin')\n",
    "labels_path = os.path.join(dataset_path, 'label_2', rf'{pointcloud_file}.txt')\n",
    "\n",
    "pointcloud = read_bin(pointcloud_fullpath)\n",
    "\n",
    "label_data = pd.read_csv(labels_path, sep=' ', header=None, names=['type', 'truncated', 'occluded', 'alpha', 'bbox_left', 'bbox_top', 'bbox_right', 'bbox_bottom',\n",
    "                                                                     'height_object', 'width_object', 'length_object', 'location_x_camera', 'location_y_camera', \n",
    "                                                                     'location_z_camera', 'rotation_y'])\n",
    "label_data = label_data[label_data['type']!='DontCare']\n",
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.226002</td>\n",
       "      <td>6.967</td>\n",
       "      <td>2.259</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.341000</td>\n",
       "      <td>7.173</td>\n",
       "      <td>2.264</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.366001</td>\n",
       "      <td>7.368</td>\n",
       "      <td>2.266</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.824001</td>\n",
       "      <td>7.744</td>\n",
       "      <td>2.316</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.334999</td>\n",
       "      <td>7.781</td>\n",
       "      <td>2.300</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121888</th>\n",
       "      <td>3.713000</td>\n",
       "      <td>-1.424</td>\n",
       "      <td>-1.738</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121889</th>\n",
       "      <td>3.722000</td>\n",
       "      <td>-1.415</td>\n",
       "      <td>-1.741</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121890</th>\n",
       "      <td>3.735000</td>\n",
       "      <td>-1.406</td>\n",
       "      <td>-1.745</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121891</th>\n",
       "      <td>3.621000</td>\n",
       "      <td>-1.356</td>\n",
       "      <td>-1.687</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121892</th>\n",
       "      <td>3.754000</td>\n",
       "      <td>-1.393</td>\n",
       "      <td>-1.751</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121893 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                X      Y      Z     I\n",
       "0       60.226002  6.967  2.259  0.00\n",
       "1       60.341000  7.173  2.264  0.00\n",
       "2       60.366001  7.368  2.266  0.03\n",
       "3       61.824001  7.744  2.316  0.09\n",
       "4       61.334999  7.781  2.300  0.08\n",
       "...           ...    ...    ...   ...\n",
       "121888   3.713000 -1.424 -1.738  0.28\n",
       "121889   3.722000 -1.415 -1.741  0.32\n",
       "121890   3.735000 -1.406 -1.745  0.30\n",
       "121891   3.621000 -1.356 -1.687  0.00\n",
       "121892   3.754000 -1.393 -1.751  0.00\n",
       "\n",
       "[121893 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_pointcloud = pd.DataFrame(pointcloud, columns=['X', 'Y', 'Z', 'I'])\n",
    "pd_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary = {\n",
    "    \"minX\": 0,\n",
    "    \"maxX\": 50,\n",
    "    \"minY\": -25,\n",
    "    \"maxY\": 25,\n",
    "    \"minZ\": -2.73,\n",
    "    \"maxZ\": 1.27\n",
    "}\n",
    "\n",
    "def removePoints(PointCloud, BoundaryCond):\n",
    "    # Boundary condition\n",
    "    minX = BoundaryCond['minX']\n",
    "    maxX = BoundaryCond['maxX']\n",
    "    minY = BoundaryCond['minY']\n",
    "    maxY = BoundaryCond['maxY']\n",
    "    minZ = BoundaryCond['minZ']\n",
    "    maxZ = BoundaryCond['maxZ']\n",
    "\n",
    "    # Remove the point out of range x,y,z\n",
    "    mask = np.where((PointCloud[:, 0] >= minX) & (PointCloud[:, 0] <= maxX) & (PointCloud[:, 1] >= minY) & (\n",
    "            PointCloud[:, 1] <= maxY) & (PointCloud[:, 2] >= minZ) & (PointCloud[:, 2] <= maxZ))\n",
    "    PointCloud = PointCloud[mask]\n",
    "\n",
    "    return PointCloud\n",
    "\n",
    "pointcloud = removePoints(pointcloud, boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://github.com/HengLan/Visualize-KITTI-Objects-in-Videos/blob/main/utility.py#L45\n",
    "# https://github.com/HengLan/Visualize-KITTI-Objects-in-Videos/blob/main/KITTI.py#L269\n",
    "def transform_3dbox_to_pointcloud(dimension, location, rotation):\n",
    "    \"\"\"\n",
    "    convert the 3d box to coordinates in pointcloud\n",
    "    :param dimension: height, width, and length\n",
    "    :param location: x, y, and z\n",
    "    :param rotation: rotation parameter\n",
    "    :return: transformed coordinates\n",
    "    \"\"\"\n",
    "    height, width, lenght = dimension\n",
    "    x_offset = 0#lenght/2 #/ 2\n",
    "    y_offset = 0.2#height / 4\n",
    "    z_offset = 0#width/2 #/ 2\n",
    "\n",
    "    x, y, z = location\n",
    "    x_corners = [lenght/2 + x_offset, lenght/2 + x_offset, -lenght/2 - x_offset, -lenght/2 - x_offset,  lenght/2 + x_offset,  lenght/2 + x_offset, -lenght/2 - x_offset, -lenght/2 - x_offset]\n",
    "    y_corners = [y_offset, y_offset, y_offset, y_offset, -height - y_offset, -height - y_offset, -height - y_offset, -height - y_offset]\n",
    "    z_corners = [width/2 + z_offset, -width/2 - z_offset, -width/2 - z_offset, width/2 + z_offset, width/2 + z_offset, -width/2 - z_offset, -width/2 - z_offset, width/2 + z_offset]\n",
    "\n",
    "    corners_3d = np.vstack([x_corners, y_corners, z_corners])\n",
    "\n",
    "    # transform 3d box based on rotation along Y-axis\n",
    "    R_matrix = np.array([[np.cos(rotation), 0, np.sin(rotation)],\n",
    "                         [0, 1, 0],\n",
    "                         [-np.sin(rotation), 0, np.cos(rotation)]])\n",
    "\n",
    "    corners_3d = np.dot(R_matrix, corners_3d).T\n",
    "\n",
    "    # shift the corners to from origin to location\n",
    "    corners_3d = corners_3d + np.array([x, y, z])\n",
    "\n",
    "    # from camera coordinate to velodyne coordinate\n",
    "    corners_3d = corners_3d[:, [2, 0, 1]] * np.array([[1, -1, -1]])\n",
    "\n",
    "    return corners_3d\n",
    "\n",
    "def get_3d_corners(label_data):\n",
    "    ''' x-axis points to the front\n",
    "        y-axis points to left\n",
    "        corners: (8,3) array of vertices for the 3d box in following order [X, Y, Z]:\n",
    "            6 -------- 7\n",
    "           /|         /|\n",
    "          5 -------- 4 .\n",
    "          | |        | |\n",
    "          . 0 -------- 1\n",
    "          |/         |/\n",
    "          3 -------- 2\n",
    "    '''\n",
    "    corners_3d = []\n",
    "    for i in range(len(label_data.axes[0])):\n",
    "        dimension = [label_data.iloc[i].height_object, label_data.iloc[i].width_object, label_data.iloc[i].length_object]\n",
    "        location = [label_data.iloc[i].location_x_camera, label_data.iloc[i].location_y_camera, label_data.iloc[i].location_z_camera]\n",
    "        rotation = label_data.iloc[i].rotation_y\n",
    "\n",
    "        corners_3d.append(transform_3dbox_to_pointcloud(dimension, location, rotation))                                                                                          \n",
    "        #corners_3d.append([transform_3dbox_to_pointcloud(dimension, location, rotation), rotation])\n",
    "    return corners_3d\n",
    "\n",
    "corners_all = get_3d_corners(label_data)\n",
    "#print(corners_all[0])\n",
    "#print(len(corners_all[0]))\n",
    "#print(len(corners_all))\n",
    "\n",
    "#for idx, corners in enumerate(corners_all):\n",
    "#    print(idx, corners[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             X      Y      Z     I\n",
      "0    14.911000  8.194 -0.340  0.27\n",
      "1    14.904000  8.251 -0.341  0.33\n",
      "2    14.923000  8.292 -0.342  0.38\n",
      "3    14.923000  8.354 -0.343  0.37\n",
      "4    14.924000  8.416 -0.344  0.34\n",
      "..         ...    ...    ...   ...\n",
      "790  48.724998  8.445 -1.378  0.00\n",
      "791  48.747002  8.606 -1.380  0.00\n",
      "792  48.519001  8.881 -1.374  0.16\n",
      "793  48.360001  8.930 -1.370  0.00\n",
      "794  48.459000  9.106 -1.374  0.00\n",
      "\n",
      "[795 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Lento, pero SI extrae exactamente los puntos dentro del bbox aunque esten desalineados con el centro del mundo\n",
    "'''\n",
    "If your cube vertices are not aligned with the world coordinate system (i.e., they are in arbitrary orientations), you will need to use a more complex approach\n",
    "to determine if a point is inside the cube. One common method is to use the concept of convex hulls. Here's how you can approach this problem:\n",
    "\n",
    "Find the convex hull of the cube: The convex hull is the smallest convex shape that contains all the cube's vertices.\n",
    "You can use algorithms like the QuickHull algorithm or the Gift Wrapping algorithm to find the convex hull of your cube's vertices.\n",
    "\n",
    "Check if the point is inside the convex hull: Once you have the convex hull, you can check if the point is inside it. \n",
    "You can use the point-in-polygon test to determine this.\n",
    "'''\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "def filter_points(pointcloud, corners):\n",
    "    filtered_points = pd.DataFrame(columns=['X', 'Y', 'Z', 'I'])\n",
    "\n",
    "    # Find the convex hull of the cube's vertices\n",
    "    hull = ConvexHull(corners)\n",
    "\n",
    "    # Check if the point is inside the convex hull  \n",
    "    delaunay_triangulation = Delaunay(hull.points[hull.vertices])\n",
    "    for i, point in enumerate(pointcloud):\n",
    "        simplex = delaunay_triangulation.find_simplex(point[:-1])\n",
    "        if simplex >= 0:\n",
    "            filtered_points.loc[i] = point\n",
    "    return filtered_points\n",
    "\n",
    "for idx, corners in enumerate(corners_all):\n",
    "    filtered_points = filter_points(pointcloud, corners)\n",
    "\n",
    "    #Add 3d box vertices to visualize it\n",
    "    corners_pd = pd.DataFrame(corners, columns = ['X','Y','Z'])\n",
    "    corners_pd['I'] = 0.0\n",
    "    \n",
    "    #point=0\n",
    "    if idx == 0:\n",
    "        filtered_pointcloud = filtered_points.copy()\n",
    "        filtered_pointcloud_with_bbox = filtered_points.copy()\n",
    "        #filtered_pointcloud_with_bbox = pd.concat([filtered_pointcloud_with_bbox, corners_pd.iloc[[point]]], ignore_index=True)\n",
    "        filtered_pointcloud_with_bbox = pd.concat([filtered_pointcloud_with_bbox, corners_pd], ignore_index=True)\n",
    "    else:\n",
    "        filtered_pointcloud = pd.concat([filtered_pointcloud, filtered_points], ignore_index=True)\n",
    "        filtered_pointcloud_with_bbox = pd.concat([filtered_pointcloud_with_bbox, filtered_points], ignore_index=True)\n",
    "        filtered_pointcloud_with_bbox = pd.concat([filtered_pointcloud_with_bbox, corners_pd], ignore_index=True)\n",
    "\n",
    "filtered_pointcloud.reset_index(inplace=True)\n",
    "filtered_pointcloud.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "print(filtered_pointcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               X      Y      Z     I\n",
      "0       3.607000  2.640 -0.105  0.00\n",
      "1       3.577000  2.661 -0.105  0.00\n",
      "2       3.542000  2.705 -0.104  0.00\n",
      "3       3.524000  2.727 -0.104  0.00\n",
      "4       3.490000  2.709 -0.102  0.00\n",
      "...          ...    ...    ...   ...\n",
      "22088  18.143000 -6.773 -1.702  0.29\n",
      "22089  17.337000 -7.523 -1.772  0.32\n",
      "22090  17.372999 -7.474 -1.774  0.36\n",
      "22091  17.337999 -7.394 -1.767  0.32\n",
      "22092  17.295000 -7.312 -1.760  0.33\n",
      "\n",
      "[22093 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Otra opción pero no da bien el resultado\n",
    "def is_point_inside_cube(cube_vertices, inv_rotation_matrix, point):\n",
    "    \n",
    "    # Transform the cube vertices\n",
    "    transformed_cube_vertices = np.dot(inv_rotation_matrix, cube_vertices.T).T\n",
    "    \n",
    "    # Transform the point\n",
    "    transformed_point = np.dot(inv_rotation_matrix, point)\n",
    "\n",
    "    # Calculate the boundaries of the transformed cube\n",
    "    min_x = np.min(transformed_cube_vertices[:, 0])\n",
    "    max_x = np.max(transformed_cube_vertices[:, 0])\n",
    "    min_y = np.min(transformed_cube_vertices[:, 1])\n",
    "    max_y = np.max(transformed_cube_vertices[:, 1])\n",
    "    min_z = np.min(transformed_cube_vertices[:, 2])\n",
    "    max_z = np.max(transformed_cube_vertices[:, 2])\n",
    "\n",
    "    # Check if the transformed point is inside the transformed cube\n",
    "    return (\n",
    "        min_x <= transformed_point[0] <= max_x and\n",
    "        min_y <= transformed_point[1] <= max_y and\n",
    "        min_z <= transformed_point[2] <= max_z\n",
    "    )\n",
    "\n",
    "def filter_points(pointcloud, corners, inv_rotation_matrix):\n",
    "    filtered_points = pd.DataFrame(columns=['X', 'Y', 'Z', 'I'])\n",
    "    for i, point in enumerate(pointcloud):       \n",
    "        if is_point_inside_cube(corners, inv_rotation_matrix, point[:-1]): #Point must be [X,Y,Z] without I\n",
    "            filtered_points.loc[i] = point\n",
    "    return filtered_points\n",
    "\n",
    "for idx, corners in enumerate(corners_all):\n",
    "    R_matrix = np.array([[np.cos(corners[1]), 0, np.sin(corners[1])],\n",
    "                         [0, 1, 0],\n",
    "                         [-np.sin(corners[1]), 0, np.cos(corners[1])]])\n",
    "\n",
    "    # Inverse of the rotation matrix\n",
    "    inv_rotation_matrix = np.linalg.inv(R_matrix)\n",
    "\n",
    "    filtered_points = filter_points(pointcloud, corners[0], inv_rotation_matrix)\n",
    "\n",
    "    #Add 3d box vertices to visualize it\n",
    "    corners_pd = pd.DataFrame(corners[0], columns = ['X','Y','Z'])\n",
    "    corners_pd['I'] = 0.0\n",
    "    \n",
    "    #point=0\n",
    "    if idx == 0:\n",
    "        filtered_pointcloud = filtered_points.copy()\n",
    "        filtered_pointcloud_with_bbox = filtered_points.copy()\n",
    "        #filtered_pointcloud_with_bbox = pd.concat([filtered_pointcloud_with_bbox, corners_pd.iloc[[point]]], ignore_index=True)\n",
    "        filtered_pointcloud_with_bbox = pd.concat([filtered_pointcloud_with_bbox, corners_pd], ignore_index=True)\n",
    "    else:\n",
    "        filtered_pointcloud = pd.concat([filtered_pointcloud, filtered_points], ignore_index=True)\n",
    "        filtered_pointcloud_with_bbox = pd.concat([filtered_pointcloud_with_bbox, filtered_points], ignore_index=True)\n",
    "        filtered_pointcloud_with_bbox = pd.concat([filtered_pointcloud_with_bbox, corners_pd], ignore_index=True)\n",
    "\n",
    "filtered_pointcloud.reset_index(inplace=True)\n",
    "filtered_pointcloud.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "print(filtered_pointcloud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121893, 4)\n",
      "(8, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(121893, 4)\n",
      "(8, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "             X      Y      Z     I\n",
      "0    14.911000  8.194 -0.340  0.27\n",
      "1    14.904000  8.251 -0.341  0.33\n",
      "2    14.923000  8.292 -0.342  0.38\n",
      "3    14.923000  8.354 -0.343  0.37\n",
      "4    14.924000  8.416 -0.344  0.34\n",
      "..         ...    ...    ...   ...\n",
      "803  48.724998  8.445 -1.378  0.00\n",
      "804  48.747002  8.606 -1.380  0.00\n",
      "805  48.519001  8.881 -1.374  0.16\n",
      "806  48.360001  8.930 -1.370  0.00\n",
      "807  48.459000  9.106 -1.374  0.00\n",
      "\n",
      "[808 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Eficiente, pero no extrae exactamente los puntos dentro del bbox porque los bbox no estan alineados con el centro del mundo\n",
    "\n",
    "def filter_points(pd_pointcloud, corners):\n",
    "    print(pd_pointcloud.shape)\n",
    "    print(corners.shape)\n",
    "    filtered_points = pd_pointcloud[(corners[:,0].min() < pd_pointcloud['X']) & (pd_pointcloud['X'] < corners[:,0].max())\n",
    "                                      & (corners[:,1].min() < pd_pointcloud['Y']) & (pd_pointcloud['Y'] < corners[:,1].max())\n",
    "                                      & (corners[:,2].min() < pd_pointcloud['Z']) & (pd_pointcloud['Z'] < corners[:,2].max())]\n",
    "    print(type(filtered_points))\n",
    "    return filtered_points\n",
    "\n",
    "for idx, corners in enumerate(corners_all):\n",
    "    filtered_points = filter_points(pd_pointcloud, corners)\n",
    "    \n",
    "    #Add 3d box vertices to visualize it\n",
    "    corners_pd = pd.DataFrame(corners, columns = ['X','Y','Z'])\n",
    "    corners_pd['I'] = 0.0\n",
    "    \n",
    "    #point=0\n",
    "    if idx == 0:\n",
    "        filtered_pointcloud = filtered_points.copy()\n",
    "        filtered_pointcloud_with_bbox = filtered_points.copy()\n",
    "        #filtered_pointcloud_with_bbox = pd.concat([filtered_pointcloud_with_bbox, corners_pd.iloc[[point]]], ignore_index=True)\n",
    "        filtered_pointcloud_with_bbox = pd.concat([filtered_pointcloud_with_bbox, corners_pd], ignore_index=True)\n",
    "    else:\n",
    "        filtered_pointcloud = pd.concat([filtered_pointcloud, filtered_points], ignore_index=True)\n",
    "        filtered_pointcloud_with_bbox = pd.concat([filtered_pointcloud_with_bbox, filtered_points], ignore_index=True)\n",
    "        filtered_pointcloud_with_bbox = pd.concat([filtered_pointcloud_with_bbox, corners_pd], ignore_index=True)\n",
    "\n",
    "filtered_pointcloud.reset_index(inplace=True)\n",
    "filtered_pointcloud.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "print(filtered_pointcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121893, 4)\n",
      "(808, 4)\n",
      "(121085, 4)\n"
     ]
    }
   ],
   "source": [
    "def get_outer_points(pd_pointcloud, filtered_pointcloud):\n",
    "\n",
    "    # Crear los DataFrames de ejemplo\n",
    "    df1 = pd_pointcloud.copy()\n",
    "    df2 = filtered_pointcloud.copy()\n",
    "\n",
    "    # Realizar un merge con indicator=True\n",
    "    merged = df1.merge(df2, how='outer', indicator=True)\n",
    "\n",
    "    # Filtrar las filas que están en ambos DataFrames\n",
    "    result = merged[merged['_merge'] == 'both']\n",
    "    # Eliminar las filas repetidas de df1\n",
    "    df1 = df1[~df1.isin(result.to_dict('list')).all(1)]\n",
    "\n",
    "    # Eliminar las filas repetidas de df2 (opcional)\n",
    "    #df2 = df2[~df2.isin(result.to_dict('list')).all(1)]\n",
    "\n",
    "    return df1\n",
    "\n",
    "a = get_outer_points(pd_pointcloud, filtered_pointcloud)\n",
    "#print(pd_pointcloud.shape)\n",
    "#print(filtered_pointcloud.shape)\n",
    "#print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.911000</td>\n",
       "      <td>8.194</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.904000</td>\n",
       "      <td>8.251</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.923000</td>\n",
       "      <td>8.292</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.923000</td>\n",
       "      <td>8.354</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.924000</td>\n",
       "      <td>8.416</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>48.724998</td>\n",
       "      <td>8.445</td>\n",
       "      <td>-1.378</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>48.747002</td>\n",
       "      <td>8.606</td>\n",
       "      <td>-1.380</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>48.519001</td>\n",
       "      <td>8.881</td>\n",
       "      <td>-1.374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>48.360001</td>\n",
       "      <td>8.930</td>\n",
       "      <td>-1.370</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>48.459000</td>\n",
       "      <td>9.106</td>\n",
       "      <td>-1.374</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>808 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X      Y      Z     I\n",
       "0    14.911000  8.194 -0.340  0.27\n",
       "1    14.904000  8.251 -0.341  0.33\n",
       "2    14.923000  8.292 -0.342  0.38\n",
       "3    14.923000  8.354 -0.343  0.37\n",
       "4    14.924000  8.416 -0.344  0.34\n",
       "..         ...    ...    ...   ...\n",
       "803  48.724998  8.445 -1.378  0.00\n",
       "804  48.747002  8.606 -1.380  0.00\n",
       "805  48.519001  8.881 -1.374  0.16\n",
       "806  48.360001  8.930 -1.370  0.00\n",
       "807  48.459000  9.106 -1.374  0.00\n",
       "\n",
       "[808 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r'D:\\Nicolas\\reducida.ply'\n",
    "save_ply(filtered_pointcloud.to_numpy(), save_path)\n",
    "\n",
    "save_path = r'D:\\Nicolas\\reducida_with_bbox.ply'\n",
    "save_ply(filtered_pointcloud_with_bbox.to_numpy(), save_path)\n",
    "\n",
    "save_path_or = r'D:\\Nicolas\\original.ply'\n",
    "save_ply(pointcloud, save_path_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Loss Module Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'D:\\Nicolas\\Posgrado\\Trabajos y Tesis\\LIDAR\\LIDAR_super_resolution\\Scripts\\otras_arquitecturas\\3_pytorch_interpolation')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import kaolin\n",
    "from object_filtering import pointcloud_filter\n",
    "from pointcloud_utils_functions_v2 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChamferLoss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(ChamferLoss, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, image_pred, image_gt, label_path):\n",
    "        \"\"\"\n",
    "        Compute the Chamfer distance between predicted and ground truth point clouds.\n",
    "\n",
    "        Args:\n",
    "            point_cloud_pred (torch.Tensor): Predicted point cloud tensor of shape (batch_size, num_points, num_dims).\n",
    "            point_cloud_gt (torch.Tensor): Ground truth point cloud tensor of shape (batch_size, num_points, num_dims).\n",
    "        Returns:\n",
    "            torch.Tensor: Chamfer distance loss.\n",
    "        \"\"\"\n",
    "        image_pred = image_pred.to(device)\n",
    "        image_gt = image_gt.to(device)\n",
    "\n",
    "        pointcloud_pred = range_image_to_pointcloud_pytorch(image_pred, device)\n",
    "        pointcloud_gt = range_image_to_pointcloud_pytorch(image_gt, device)\n",
    "\n",
    "        pointcloud_np_pred_filtered, pointcloud_np_pred_non_filtered = pointcloud_filter(pointcloud_pred.cpu().numpy()[0], label_path)\n",
    "        pointcloud_pred_filtered = torch.from_numpy(pointcloud_np_pred_filtered).unsqueeze(0)#.unsqueeze(0) #[batch, num_points, 4]\n",
    "        pointcloud_pred_non_filtered = torch.from_numpy(pointcloud_np_pred_non_filtered).unsqueeze(0)#.unsqueeze(0) #[batch, num_points, 4]\n",
    "\n",
    "        pointcloud_np_gt_filtered, pointcloud_np_get_non_filtered = pointcloud_filter(pointcloud_gt.cpu().numpy()[0], label_path)\n",
    "        pointcloud_gt_filtered = torch.from_numpy(pointcloud_np_gt_filtered).unsqueeze(0) #[batch, num_points, 4]\n",
    "        pointcloud_gt_non_filtered = torch.from_numpy(pointcloud_np_get_non_filtered).unsqueeze(0) #[batch, num_points, 4]\n",
    "        \n",
    "        chamfer_loss_filtered = kaolin.metrics.pointcloud.chamfer_distance(pointcloud_pred_filtered[:,:,:3].to(self.device), pointcloud_gt_filtered[:,:,:3].to(self.device))\n",
    "        chamfer_loss_non_filtered = kaolin.metrics.pointcloud.chamfer_distance(pointcloud_pred_non_filtered[:,:,:3].to(self.device), pointcloud_gt_non_filtered[:,:,:3].to(self.device))\n",
    "        \n",
    "        chamfer_loss_mean = torch.mean(chamfer_loss_filtered) * 0.7 + torch.mean(chamfer_loss_non_filtered) * 0.3\n",
    "\n",
    "        return chamfer_loss_mean\n",
    "\n",
    "device = 'cuda'\n",
    "loss_fn = ChamferLoss(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.9171, -6.4779, -5.2000],\n",
      "        [ 3.2962, -3.9535, -5.2000],\n",
      "        [ 7.0829, -1.5221, -5.2000],\n",
      "        [ 8.7038, -4.0465, -5.2000],\n",
      "        [ 4.9171, -6.4779, -3.8000],\n",
      "        [ 3.2962, -3.9535, -3.8000],\n",
      "        [ 7.0829, -1.5221, -3.8000],\n",
      "        [ 8.7038, -4.0465, -3.8000]])\n"
     ]
    }
   ],
   "source": [
    "dataset_path = r'D:\\Nicolas\\Posgrado\\Trabajos y Tesis\\LIDAR\\Datasets LIDAR\\kitti\\kitti_3d_object\\training'\n",
    "pointcloud_fullpath = dataset_path + r'\\velodyne\\000034.bin'\n",
    "labels_path = dataset_path + r'\\label_2\\000034.txt'\n",
    "pointcloud = read_bin(pointcloud_fullpath)\n",
    "range_image = pointcloud_to_range_image(pointcloud, size=(64, 2048))\n",
    "range_image = torch.from_numpy(range_image).unsqueeze(0) #[batch, channel, height, width]\n",
    "\n",
    "pointcloud_fullpath_2 = dataset_path + r'\\velodyne\\000035.bin'\n",
    "labels_path_2 = dataset_path + r'\\label_2\\000035.txt'\n",
    "pointcloud_2 = read_bin(pointcloud_fullpath_2)\n",
    "range_image_2 = pointcloud_to_range_image(pointcloud_2, size=(64, 2048))\n",
    "range_image_2 = torch.from_numpy(range_image_2).unsqueeze(0) #[batch, channel, height, width]\n",
    "\n",
    "range_image_batch = torch.stack((range_image, range_image_2), dim=0) #[batch, channels, height, width] [2,1,64,2048]\n",
    "############################### HASTA AQUI ESTAMOS EN EL MUNDO DE LAS IMÁGENES#####################################\n",
    "\n",
    "pointcloud_batch = range_image_to_pointcloud_pytorch(range_image_batch.to(device), device='cuda') #[batch, num_points, 4]\n",
    "\n",
    "def removePoints(PointCloud):\n",
    "    # Remove the point out of range x,y,z\n",
    "    BoundaryCond = {\"minX\": 0, \"maxX\": 50, \"minY\": -25, \"maxY\": 25, \"minZ\": -2.73, \"maxZ\": 1.27}\n",
    "\n",
    "    masks = (\n",
    "        (PointCloud[:, :, 0] >= BoundaryCond['minX']) & \n",
    "        (PointCloud[:, :, 0] <= BoundaryCond['maxX']) & \n",
    "        (PointCloud[:, :, 1] >= BoundaryCond['minY']) & \n",
    "        (PointCloud[:, :, 1] <= BoundaryCond['maxY']) & \n",
    "        (PointCloud[:, :, 2] >= BoundaryCond['minZ']) & \n",
    "        (PointCloud[:, :, 2] <= BoundaryCond['maxZ'])\n",
    "    )\n",
    "\n",
    "    # Apply the masks to filter the points in each point cloud\n",
    "    filtered_point_clouds = [PointCloud[mask] for PointCloud, mask in zip(PointCloud, masks)]\n",
    "\n",
    "    return filtered_point_clouds\n",
    "\n",
    "#pointcloud_removed = removePoints(pointcloud_batch)\n",
    "\n",
    "def transform_3dbox_to_pointcloud(dimension, location, rotation):\n",
    "    \"\"\"\n",
    "    #source: https://github.com/HengLan/Visualize-KITTI-Objects-in-Videos/blob/main/utility.py#L45\n",
    "    # https://github.com/HengLan/Visualize-KITTI-Objects-in-Videos/blob/main/KITTI.py#L269\n",
    "    convert the 3d box to coordinates in pointcloud\n",
    "    :param dimension: height, width, and length\n",
    "    :param location: x, y, and z\n",
    "    :param rotation: rotation parameter\n",
    "    :return: transformed coordinates\n",
    "    \"\"\"\n",
    "    height, width, length = dimension\n",
    "    x_offset = length/4 #/ 2\n",
    "    y_offset = 0.2#height / 4\n",
    "    z_offset = width/4 #/ 2\n",
    "\n",
    "    x, y, z = location\n",
    "    x_corners = torch.tensor([length / 2 + x_offset, length / 2 + x_offset, -length / 2 - x_offset, -length / 2 - x_offset,\n",
    "                              length / 2 + x_offset, length / 2 + x_offset, -length / 2 - x_offset, -length / 2 - x_offset])\n",
    "    y_corners = torch.tensor([y_offset, y_offset, y_offset, y_offset, -height - y_offset, -height - y_offset, -height - y_offset, -height - y_offset])\n",
    "    z_corners = torch.tensor([width / 2 + z_offset, -width / 2 - z_offset, -width / 2 - z_offset, width / 2 + z_offset,\n",
    "                              width / 2 + z_offset, -width / 2 - z_offset, -width / 2 - z_offset, width / 2 + z_offset])\n",
    "\n",
    "    # Create a tensor of corners_3d\n",
    "    corners_3d = torch.stack([x_corners, y_corners, z_corners])\n",
    "\n",
    "    # transform 3d box based on rotation along Y-axis\n",
    "    rotation_matrix = torch.tensor([[torch.cos(rotation), 0, torch.sin(rotation)],\n",
    "                                    [0, 1, 0],\n",
    "                                    [-torch.sin(rotation), 0, torch.cos(rotation)]])\n",
    "\n",
    "    corners_3d = torch.transpose(torch.mm(rotation_matrix, corners_3d), 0, 1)\n",
    "\n",
    "    # shift the corners to from origin to location\n",
    "    corners_3d = corners_3d + torch.tensor([x, y, z])\n",
    "\n",
    "    # from camera coordinate to velodyne coordinate\n",
    "    corners_3d = corners_3d[:, [2, 0, 1]] * torch.tensor([[1.0, -1.0, -1.0]])\n",
    "\n",
    "    return corners_3d\n",
    "\n",
    "\n",
    "dimension = torch.tensor([1.0, 2.0, 3.0])\n",
    "location = torch.tensor([4.0, 5.0, 6.0])\n",
    "rotation = torch.tensor(1.0)\n",
    "\n",
    "result = transform_3dbox_to_pointcloud(dimension, location, rotation)\n",
    "print(result)\n",
    "\n",
    "def get_3d_corners(label_data):\n",
    "    ''' x-axis points to the front\n",
    "        y-axis points to left\n",
    "        corners: (8,3) array of vertices for the 3d box in following order [X, Y, Z]:\n",
    "            6 -------- 7\n",
    "           /|         /|\n",
    "          5 -------- 4 .\n",
    "          | |        | |\n",
    "          . 0 -------- 1\n",
    "          |/         |/\n",
    "          3 -------- 2\n",
    "    '''\n",
    "    corners_3d = []\n",
    "    for i in range(len(label_data.axes[0])):\n",
    "        dimension = [label_data.iloc[i].height_object, label_data.iloc[i].width_object, label_data.iloc[i].length_object]\n",
    "        location = [label_data.iloc[i].location_x_camera, label_data.iloc[i].location_y_camera, label_data.iloc[i].location_z_camera]\n",
    "        rotation = label_data.iloc[i].rotation_y\n",
    "\n",
    "        corners_3d.append(transform_3dbox_to_pointcloud(dimension, location, rotation))                                                                                          \n",
    "\n",
    "    return corners_3d\n",
    "\n",
    "#save_path = r'D:\\Nicolas\\a.ply'\n",
    "#save_ply(pointcloud_removed[1].cpu().numpy(), save_path)\n",
    "\n",
    "\n",
    "#error = loss_fn(range_image_batch, range_image_batch, labels_path)\n",
    "#print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from data_gen_distance import *\n",
    "from pointcloud_utils_functions_v2 import *\n",
    "import time\n",
    "\n",
    "class IterDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, generator):\n",
    "        self.generator = generator\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.generator()\n",
    "\n",
    "batch_size=2\n",
    "train_dataset = IterDataset(train_data_generator)\n",
    "valid_dataset = IterDataset(valid_data_generator)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size)\n",
    "\n",
    "lr, hr, labels_path = next(iter(train_dataloader))\n",
    "labels = read_labels(labels_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('pointcloud_upsampling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "402cbac5888b33cf79a214eb8c201956a37e5ef9aca55333b119a6be878a710a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
